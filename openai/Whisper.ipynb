{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper è¯­éŸ³è¯†åˆ«"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŠŸèƒ½\n",
    "* å°†éŸ³é¢‘è½¬å½•æˆéŸ³é¢‘æ‰€ä½¿ç”¨çš„ä»»ä½•è¯­è¨€ã€‚\n",
    "* å°†éŸ³é¢‘ç¿»è¯‘å¹¶è½¬å½•æˆè‹±æ–‡ã€‚\n",
    "\n",
    "æ–‡ä»¶ä¸Šä¼ ç›®å‰é™åˆ¶ä¸º 25 MBï¼Œå¹¶ä¸”æ”¯æŒä»¥ä¸‹è¾“å…¥æ–‡ä»¶ç±»å‹ï¼šmp3, mp4, mpeg, mpga, m4a, wav, and webm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æµ‹è¯•\n",
    "### è¯­éŸ³æ–‡ä»¶ï¼šdata/audios/test.m4a\n",
    "### è¯­éŸ³å†…å®¹ï¼š\n",
    "Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ï¼Œå¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚\n",
    "\n",
    "å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ï¼Œå¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·ï¼Œè€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚\n",
    "\n",
    "å¥¹æŒ‡å‡ºï¼Œäººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡ï¼Œå› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒï¼Œä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼ï¼Œå°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miramuratiæ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢– ä»–çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ ä»–è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…· è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…· ä»–æŒ‡å‡ºäººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡ å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒ ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼ å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "audio_file= open(\"../data/audios/test.m4a\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "print(transcript[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘ å¯ä»¥çœ‹åˆ°è½¬æ¢çš„éå¸¸å‡†ç¡®ï¼Œä½†æ˜¯ç¼ºå°‘äº†æ ‡ç‚¹ç¬¦å·ï¼Œè‹±æ–‡åå­—ä¹Ÿæœ‰ä¸€ç‚¹å°å°çš„é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mira Muratiæ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„, å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·, è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡, å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒ, ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚ äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼, å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "audio_file= open(\"../data/audios/test.m4a\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file,\n",
    "                                     prompt=\"æ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\")\n",
    "print(transcript[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸­è‹±æ–‡æ··æ’æœ‰æ—¶å€™å–œæ¬¢ä¸­æ–‡å’Œè‹±æ–‡ä¹‹é—´åŠ ä¸Šç©ºæ ¼ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æç¤ºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ã€‚ å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·, è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡, å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒ, ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚ äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼, å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "audio_file= open(\"../data/audios/test.m4a\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file,\n",
    "                                     prompt=\"æ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\")\n",
    "print(transcript[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™é‡Œè¿˜æœ‰ä¸ªå°é—®é¢˜ï¼Œæ¯ä¸ªæ ‡ç‚¹ç¬¦å·åé¢éƒ½æœ‰ä¸€ä¸ªç©ºæ ¼ã€‚è¿™ä¸ªå°é—®é¢˜ä¸å¥½è§£å†³å•Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„, å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·, è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡, å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒ, ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚ äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼, å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "audio_file= open(\"../data/audios/test.m4a\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file,\n",
    "                                     prompt=\"å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\")\n",
    "print(transcript[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ›´é•¿çš„è¾“å…¥\n",
    "\n",
    "é»˜è®¤æƒ…å†µä¸‹ï¼ŒWhisper API ä»…æ”¯æŒå°äº 25 MB çš„æ–‡ä»¶ã€‚å¦‚æœæ‚¨æœ‰æ¯”è¿™æ›´é•¿çš„éŸ³é¢‘æ–‡ä»¶ï¼Œåˆ™éœ€è¦å°†å…¶åˆ†æˆ 25 MB æˆ–æ›´å°çš„å—æˆ–ä½¿ç”¨å‹ç¼©éŸ³é¢‘æ ¼å¼ã€‚ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨é¿å…åœ¨å¥å­ä¸­é—´æ‰“æ–­éŸ³é¢‘ï¼Œå› ä¸ºè¿™å¯èƒ½ä¼šå¯¼è‡´æŸäº›ä¸Šä¸‹æ–‡ä¸¢å¤±ã€‚\n",
    "\n",
    "ä¸€ç§å¤„ç†æ–¹æ³•æ˜¯ä½¿ç”¨ [PyDub](https://github.com/jiaaro/pydub) å¼€æº Python åŒ…æ¥åˆ†å‰²éŸ³é¢‘ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pydub\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‰‹åŠ¨åˆ†å‰²æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='tmp/test2.mp3'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "audio = AudioSegment.from_file(\"../data/audios/test.m4a\")\n",
    "\n",
    "# PyDub handles time in milliseconds\n",
    "thirty_seconds = 30 * 1000\n",
    "\n",
    "first_30_seconds = audio[:thirty_seconds]\n",
    "first_30_seconds.export(\"../tmp/test1.mp3\", format=\"mp3\")\n",
    "\n",
    "last_seconds = audio[thirty_seconds:]\n",
    "last_seconds.export(\"../tmp/test2.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„, å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·, è€Œä¸æ˜¯ä¸€ç§å·¥å…·ã€‚\n",
      "äººå·¥æ™ºèƒ½æŠ€æœ¯ä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ ä»–æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡, å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒ, ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚ äººå·¥æ™ºèƒ½æŠ€æœ¯åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼, å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "for file in [\"../tmp/test1.mp3\", \"tmp/test2.mp3\"]:\n",
    "    audio_file= open(file, \"rb\")\n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file,\n",
    "                                        prompt=\"å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\")\n",
    "    print(transcript[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¯­éŸ³å†…å®¹ï¼š\n",
    "Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ï¼Œå¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚\n",
    "\n",
    "å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ï¼Œå¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·ï¼Œè€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚\n",
    "\n",
    "å¥¹æŒ‡å‡ºï¼Œäººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡ï¼Œå› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒï¼Œä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼ï¼Œå°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯ä»¥çœ‹å‡ºæš´åŠ›åˆ†å‰²ï¼Œå¯¹äºåˆ†å‰²çš„å¥å­æ˜¯æœ‰å½±å“çš„ã€‚\n",
    "æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åœ¨æ ‡ç‚¹ç¬¦å·å¤„è¿›è¡Œåˆ†å‰²ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è·å¾—éŸ³é¢‘æ–‡ä»¶çš„é•¿åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = AudioSegment.from_file(\"../data/audios/test.m4a\")\n",
    "audio.duration_seconds # å•ä½ï¼šç§’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio) # å•ä½ï¼šæ¯«ç§’"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ’­æ”¾éŸ³é¢‘æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/gm/qdt4nkv91g3g3vb5kjtfqk2h0000gn/T/tmphym4uw6c.wav':\n",
      "  Duration: 00:01:06.67, bitrate: 768 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, 1 channels, s16, 768 kb/s\n",
      "  66.60 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pydub.playback import play\n",
    "play(audio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è‡ªåŠ¨åˆ†å‰²æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜ å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\n",
      "Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ã€‚\n",
      "ğŸ˜ Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ã€‚\n",
      "å¥¹å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·,è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡,å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒã€‚\n",
      "ğŸ˜ å¥¹å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·,è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡,å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒã€‚\n",
      "ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚ äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼, å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pydub import AudioSegment, silence\n",
    "\n",
    "def audio_transcribe(file, prompt):\n",
    "    audio_file= open(file, \"rb\")\n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, prompt=prompt)\n",
    "    return transcript[\"text\"]\n",
    "\n",
    "def detect_first_silent(audio, start_time, time_step=10, min_silence_len=500, silence_thresh=-40):\n",
    "    slice_audio = audio[start_time:start_time+time_step*1000]\n",
    "    silents = silence.detect_silence(slice_audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    if len(silents):\n",
    "        return (start_time+silents[0][0], start_time+silents[0][1])\n",
    "    return (start_time, start_time)\n",
    "\n",
    "def split_audio_file(filename, interval_seconds, save_dir):\n",
    "    audio_files = []\n",
    "\n",
    "    name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    audio = AudioSegment.from_file(filename)\n",
    "    audio_len = len(audio)\n",
    "    index = 1\n",
    "    start_time = 0\n",
    "    while start_time < audio_len:\n",
    "        end_time = start_time + interval_seconds*1000\n",
    "        if end_time > audio_len:\n",
    "            end_time = audio_len\n",
    "\n",
    "        silent_start_time, slient_end_time = detect_first_silent(audio, end_time)\n",
    "        end_time = silent_start_time\n",
    "        \n",
    "        audio_file = os.path.join(save_dir, f\"{name}{index}.mp3\")\n",
    "        audio[start_time:end_time].export(audio_file, format=\"mp3\")\n",
    "        audio_files.append(audio_file)\n",
    "\n",
    "        start_time = slient_end_time\n",
    "        index += 1\n",
    "\n",
    "    return audio_files\n",
    "\n",
    "def transcribe_audio_files(audio_files, prompt, prompt_len=100):\n",
    "    text_files = []\n",
    "    for audio_file in audio_files:\n",
    "        print(\"ğŸ˜\", prompt)\n",
    "        text = audio_transcribe(audio_file, prompt)\n",
    "        print(text)\n",
    "\n",
    "        text_file = os.path.splitext(audio_file)[0]+\".txt\"\n",
    "        with open(text_file, \"a\") as f:\n",
    "            f.write(text)\n",
    "        text_files.append(text_file)\n",
    "\n",
    "        prompt = text[-prompt_len:] if len(text) > prompt_len else text\n",
    "\n",
    "    return text_files\n",
    "\n",
    "def merge_text_files(text_files, output_file):\n",
    "    with open(output_file, \"a\") as f:\n",
    "        for text_file in text_files:\n",
    "            with open(text_file, \"r\") as f_text:\n",
    "                f.write(f_text.read())\n",
    "\n",
    "save_dir = \"../tmp\"\n",
    "\n",
    "shutil.rmtree(save_dir)\n",
    "os.mkdir(save_dir)\n",
    "\n",
    "filename = \"../data/audios/test.m4a\"\n",
    "audio_files = split_audio_file(filename, 20, save_dir)\n",
    "\n",
    "prompt = \"å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\"\n",
    "text_files = transcribe_audio_files(audio_files, prompt)\n",
    "\n",
    "text_file = os.path.join(save_dir, \"test.txt\")\n",
    "merge_text_files(text_files, text_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æœ¬åœ° Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜ å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/ai-large-models/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ã€‚\n",
      "ğŸ˜ Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/ai-large-models/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¥¹å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·,è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡,å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒã€‚\n",
      "ğŸ˜ å¥¹å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·,è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡,å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/ai-large-models/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼,å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import whisper\n",
    "from pydub import AudioSegment, silence\n",
    "\n",
    "\n",
    "def audio_transcribe_with_openai(whisper_service, file, prompt):\n",
    "    audio_file= open(file, \"rb\")\n",
    "    transcript = whisper_service.transcribe(\"whisper-1\", audio_file, prompt=prompt)\n",
    "    return transcript[\"text\"]\n",
    "\n",
    "def audio_transcribe_with_local(whisper_service, file, prompt):\n",
    "    transcript = whisper_service.transcribe(file, initial_prompt=prompt)\n",
    "    return transcript[\"text\"]\n",
    "\n",
    "def detect_first_silent(audio, start_time, time_step=10, min_silence_len=500, silence_thresh=-40):\n",
    "    slice_audio = audio[start_time:start_time+time_step*1000]\n",
    "    silents = silence.detect_silence(slice_audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    if len(silents):\n",
    "        return (start_time+silents[0][0], start_time+silents[0][1])\n",
    "    return (start_time, start_time)\n",
    "\n",
    "def split_audio_file(filename, interval_seconds, save_dir):\n",
    "    audio_files = []\n",
    "\n",
    "    name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    audio = AudioSegment.from_file(filename)\n",
    "    audio_len = len(audio)\n",
    "    index = 1\n",
    "    start_time = 0\n",
    "    while start_time < audio_len:\n",
    "        end_time = start_time + interval_seconds*1000\n",
    "        if end_time > audio_len:\n",
    "            end_time = audio_len\n",
    "\n",
    "        silent_start_time, slient_end_time = detect_first_silent(audio, end_time)\n",
    "        end_time = silent_start_time\n",
    "        \n",
    "        audio_file = os.path.join(save_dir, f\"{name}{index}.mp3\")\n",
    "        audio[start_time:end_time].export(audio_file, format=\"mp3\")\n",
    "        audio_files.append(audio_file)\n",
    "\n",
    "        start_time = slient_end_time\n",
    "        index += 1\n",
    "\n",
    "    return audio_files\n",
    "\n",
    "def transcribe_audio_files(audio_transcribe, whisper_service, audio_files, prompt, prompt_len=100):\n",
    "    text_files = []\n",
    "    for audio_file in audio_files:\n",
    "        print(\"ğŸ˜\", prompt)\n",
    "        text = audio_transcribe(whisper_service, audio_file, prompt)\n",
    "        print(text)\n",
    "\n",
    "        text_file = os.path.splitext(audio_file)[0]+\".txt\"\n",
    "        with open(text_file, \"a\") as f:\n",
    "            f.write(text)\n",
    "        text_files.append(text_file)\n",
    "\n",
    "        prompt = text[-prompt_len:] if len(text) > prompt_len else text\n",
    "\n",
    "    return text_files\n",
    "\n",
    "def merge_text_files(text_files, output_file):\n",
    "    with open(output_file, \"a\") as f:\n",
    "        for text_file in text_files:\n",
    "            with open(text_file, \"r\") as f_text:\n",
    "                f.write(f_text.read())\n",
    "\n",
    "save_dir = \"../tmp\"\n",
    "\n",
    "shutil.rmtree(save_dir)\n",
    "os.mkdir(save_dir)\n",
    "\n",
    "filename = \"../data/audios/test.m4a\"\n",
    "audio_files = split_audio_file(filename, 20, save_dir)\n",
    "\n",
    "model = whisper.load_model(\"large\")\n",
    "whisper_handlers = [(audio_transcribe_with_local, model),\n",
    "                    (audio_transcribe_with_openai, openai.Audio)]\n",
    "\n",
    "prompt = \"å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\"\n",
    "text_files = transcribe_audio_files(*whisper_handlers[0], audio_files, prompt)\n",
    "\n",
    "text_file = os.path.join(save_dir, \"test.txt\")\n",
    "merge_text_files(text_files, text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜ å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\n",
      "Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ã€‚\n",
      "ğŸ˜ Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ã€‚\n",
      "å¥¹å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·,è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡,å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒã€‚\n",
      "ğŸ˜ å¥¹å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·,è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡,å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒã€‚\n",
      "ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚ äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼, å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚\n"
     ]
    }
   ],
   "source": [
    "prompt = \"å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚\"\n",
    "text_files = transcribe_audio_files(*whisper_handlers[1], audio_files, prompt)\n",
    "\n",
    "text_file = os.path.join(save_dir, \"test.txt\")\n",
    "merge_text_files(text_files, text_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-large-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
